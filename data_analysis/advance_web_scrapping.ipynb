{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d87b5d",
   "metadata": {},
   "source": [
    "# Selenium Web Scraping Guide for Python\n",
    "\n",
    "## What is Selenium?\n",
    "\n",
    "Selenium is a powerful automation framework primarily used for testing web applications, but it's also widely used for web scraping. Unlike traditional scraping libraries like BeautifulSoup or requests, Selenium can interact with JavaScript-heavy websites by controlling a real web browser programmatically.\n",
    "\n",
    "### Key Features:\n",
    "- **Browser Automation**: Controls real browsers (Chrome, Firefox, Safari, Edge)\n",
    "- **JavaScript Support**: Can scrape dynamic content loaded by JavaScript\n",
    "- **User Interaction**: Can click buttons, fill forms, scroll pages, and simulate user behavior\n",
    "- **Cross-Platform**: Works on Windows, macOS, and Linux\n",
    "- **Multiple Language Support**: Available for Python, Java, C#, Ruby, and JavaScript\n",
    "\n",
    "## Installation\n",
    "\n",
    "### 1. Install Selenium Package\n",
    "```bash\n",
    "pip install selenium\n",
    "```\n",
    "\n",
    "### 2. Install WebDriver Manager (Recommended)\n",
    "```bash\n",
    "pip install webdriver-manager\n",
    "```\n",
    "\n",
    "### 3. Alternative: Manual WebDriver Installation\n",
    "If you prefer manual installation, download the appropriate driver:\n",
    "- **Chrome**: [ChromeDriver](https://chromedriver.chromium.org/)\n",
    "- **Firefox**: [GeckoDriver](https://github.com/mozilla/geckodriver/releases)\n",
    "- **Edge**: [EdgeDriver](https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/)\n",
    "\n",
    "## Imports and Basic Setup\n",
    "\n",
    "### Essential Imports\n",
    "```python\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "```\n",
    "\n",
    "### WebDriver Setup Options\n",
    "\n",
    "#### Option 1: Using WebDriver Manager (Recommended)\n",
    "```python\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Automatically downloads and manages ChromeDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "```\n",
    "\n",
    "#### Option 2: Manual WebDriver Path\n",
    "```python\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Specify the path to your downloaded ChromeDriver\n",
    "service = Service('/path/to/chromedriver')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "```\n",
    "\n",
    "#### Option 3: Chrome Options for Customization\n",
    "```python\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run in background\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--window-size=1920,1080')\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "```\n",
    "\n",
    "## Step-by-Step Web Scraping Process\n",
    "\n",
    "### Step 1: Initialize WebDriver\n",
    "```python\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Set up the driver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "```\n",
    "\n",
    "### Step 2: Navigate to Website\n",
    "```python\n",
    "# Open the target website\n",
    "url = \"https://example.com\"\n",
    "driver.get(url)\n",
    "\n",
    "# Optional: Maximize window\n",
    "driver.maximize_window()\n",
    "```\n",
    "\n",
    "### Step 3: Locate Elements\n",
    "Selenium provides multiple ways to find elements:\n",
    "\n",
    "```python\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# By ID\n",
    "element = driver.find_element(By.ID, \"element-id\")\n",
    "\n",
    "# By Class Name\n",
    "element = driver.find_element(By.CLASS_NAME, \"class-name\")\n",
    "\n",
    "# By Tag Name\n",
    "element = driver.find_element(By.TAG_NAME, \"div\")\n",
    "\n",
    "# By XPath\n",
    "element = driver.find_element(By.XPATH, \"//div[@class='example']\")\n",
    "\n",
    "# By CSS Selector\n",
    "element = driver.find_element(By.CSS_SELECTOR, \".class-name\")\n",
    "\n",
    "# Find multiple elements\n",
    "elements = driver.find_elements(By.CLASS_NAME, \"multiple-class\")\n",
    "```\n",
    "\n",
    "### Step 4: Extract Data\n",
    "```python\n",
    "# Get text content\n",
    "text = element.text\n",
    "\n",
    "# Get attribute values\n",
    "href = element.get_attribute(\"href\")\n",
    "src = element.get_attribute(\"src\")\n",
    "\n",
    "# Get HTML content\n",
    "html = element.get_attribute(\"innerHTML\")\n",
    "```\n",
    "\n",
    "### Step 5: Handle Dynamic Content\n",
    "```python\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Wait for element to be present\n",
    "wait = WebDriverWait(driver, 10)\n",
    "element = wait.until(EC.presence_of_element_located((By.ID, \"dynamic-content\")))\n",
    "\n",
    "# Wait for element to be clickable\n",
    "clickable_element = wait.until(EC.element_to_be_clickable((By.ID, \"button-id\")))\n",
    "```\n",
    "\n",
    "### Step 6: Interact with Elements\n",
    "```python\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Click elements\n",
    "element.click()\n",
    "\n",
    "# Send text to input fields\n",
    "input_field.send_keys(\"your text here\")\n",
    "\n",
    "# Clear input fields\n",
    "input_field.clear()\n",
    "\n",
    "# Submit forms\n",
    "form.submit()\n",
    "\n",
    "# Scroll page\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "# Press keyboard keys\n",
    "element.send_keys(Keys.ENTER)\n",
    "element.send_keys(Keys.TAB)\n",
    "```\n",
    "\n",
    "### Step 7: Handle Multiple Pages/Pagination\n",
    "```python\n",
    "# Example: Scraping multiple pages\n",
    "page_num = 1\n",
    "all_data = []\n",
    "\n",
    "while True:\n",
    "    # Scrape current page\n",
    "    elements = driver.find_elements(By.CLASS_NAME, \"data-item\")\n",
    "    \n",
    "    for element in elements:\n",
    "        data = element.text\n",
    "        all_data.append(data)\n",
    "    \n",
    "    # Try to find \"Next\" button\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, \"//a[contains(text(), 'Next')]\")\n",
    "        next_button.click()\n",
    "        time.sleep(2)  # Wait for page to load\n",
    "        page_num += 1\n",
    "    except:\n",
    "        print(f\"Scraped {page_num} pages\")\n",
    "        break\n",
    "```\n",
    "\n",
    "### Step 8: Clean Up\n",
    "```python\n",
    "# Always close the driver when done\n",
    "driver.quit()\n",
    "```\n",
    "\n",
    "## Complete Example: Scraping a News Website\n",
    "\n",
    "```python\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_news_website():\n",
    "    # Setup\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    \n",
    "    try:\n",
    "        # Navigate to website\n",
    "        driver.get(\"https://news.ycombinator.com\")\n",
    "        \n",
    "        # Wait for content to load\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        articles = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"titleline\")))\n",
    "        \n",
    "        # Extract data\n",
    "        news_data = []\n",
    "        for article in articles[:10]:  # Get first 10 articles\n",
    "            try:\n",
    "                title_element = article.find_element(By.TAG_NAME, \"a\")\n",
    "                title = title_element.text\n",
    "                link = title_element.get_attribute(\"href\")\n",
    "                \n",
    "                news_data.append({\n",
    "                    'title': title,\n",
    "                    'link': link\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting article: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Save to CSV\n",
    "        with open('news_data.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=['title', 'link'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(news_data)\n",
    "        \n",
    "        print(f\"Successfully scraped {len(news_data)} articles\")\n",
    "        return news_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Run the scraper\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_news_website()\n",
    "```\n",
    "\n",
    "## Best Practices and Tips\n",
    "\n",
    "### 1. Respect Robots.txt and Rate Limiting\n",
    "```python\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Add delays between requests\n",
    "time.sleep(random.uniform(1, 3))\n",
    "```\n",
    "\n",
    "### 2. Handle Exceptions\n",
    "```python\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "try:\n",
    "    element = driver.find_element(By.ID, \"some-id\")\n",
    "except NoSuchElementException:\n",
    "    print(\"Element not found\")\n",
    "except TimeoutException:\n",
    "    print(\"Page load timeout\")\n",
    "```\n",
    "\n",
    "### 3. Use Headless Mode for Production\n",
    "```python\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "```\n",
    "\n",
    "### 4. Implement Retry Logic\n",
    "```python\n",
    "def retry_find_element(driver, by, value, max_attempts=3):\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            return driver.find_element(by, value)\n",
    "        except NoSuchElementException:\n",
    "            if attempt == max_attempts - 1:\n",
    "                raise\n",
    "            time.sleep(1)\n",
    "```\n",
    "\n",
    "### 5. Use Context Managers\n",
    "```python\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def get_driver():\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    try:\n",
    "        yield driver\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Usage\n",
    "with get_driver() as driver:\n",
    "    driver.get(\"https://example.com\")\n",
    "    # Your scraping code here\n",
    "```\n",
    "\n",
    "## Common Challenges and Solutions\n",
    "\n",
    "### 1. CAPTCHA and Bot Detection\n",
    "- Use random delays\n",
    "- Rotate user agents\n",
    "- Use proxy servers\n",
    "- Implement human-like behavior patterns\n",
    "\n",
    "### 2. Dynamic Content Loading\n",
    "- Use WebDriverWait with expected conditions\n",
    "- Implement scroll-based loading detection\n",
    "- Monitor network activity\n",
    "\n",
    "### 3. Session Management\n",
    "- Handle cookies and sessions\n",
    "- Implement login flows\n",
    "- Maintain session state across pages\n",
    "\n",
    "### 4. Performance Optimization\n",
    "- Use headless mode\n",
    "- Disable images and CSS when not needed\n",
    "- Implement parallel processing with multiple drivers\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Selenium is a powerful tool for web scraping, especially for JavaScript-heavy websites. While it's slower than traditional HTTP-based scraping methods, its ability to interact with dynamic content makes it invaluable for many scraping tasks. Always remember to scrape responsibly and respect website terms of service and robots.txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3c1fb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 00:41:39,419 - INFO - Initializing Chrome WebDriver\n",
      "2025-06-05 00:41:40,992 - INFO - Navigating to Myntra page\n",
      "2025-06-05 00:41:59,942 - INFO - Items loaded: 50\n",
      "2025-06-05 00:42:00,668 - INFO - Clicking 'Next' or 'Load More' button\n",
      "2025-06-05 00:42:01,768 - WARNING - Button click intercepted, attempting to handle overlay\n",
      "2025-06-05 00:42:01,785 - ERROR - Failed to handle overlay\n",
      "2025-06-05 00:42:01,785 - INFO - Saving HTML content\n",
      "2025-06-05 00:42:01,895 - INFO - Scraping complete. Total items loaded: 50\n",
      "2025-06-05 00:42:01,897 - INFO - Closing WebDriver\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException, WebDriverException\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Path to chromedriver.exe\n",
    "driver_path = r'C:/Users/bhaut/Desktop/chromedriver.exe'\n",
    "service = Service(driver_path)\n",
    "\n",
    "try:\n",
    "    # Initialize Chrome WebDriver\n",
    "    logger.info(\"Initializing Chrome WebDriver\")\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    try:\n",
    "        # Navigate to the target page\n",
    "        logger.info(\"Navigating to Myntra page\")\n",
    "        driver.get('https://www.myntra.com/women-jewellery?rf=Discount%20Range%3A10.0_100.0_10.0%20TO%20100.0')\n",
    "\n",
    "        # Wait for initial page load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"results-base\"))\n",
    "        )\n",
    "\n",
    "        total_items = 0\n",
    "        target_items = 6192  # Desired number of items\n",
    "\n",
    "        while total_items < target_items:\n",
    "            try:\n",
    "                # Count current number of items\n",
    "                items = driver.find_elements(By.CLASS_NAME, \"product-base\")\n",
    "                total_items = len(items)\n",
    "                logger.info(f\"Items loaded: {total_items}\")\n",
    "\n",
    "                if total_items >= target_items:\n",
    "                    logger.info(\"Reached target number of items\")\n",
    "                    break\n",
    "\n",
    "                # Find the \"Next\" or \"Load More\" button\n",
    "                load_more_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//li[contains(@class, 'pagination-next')] | //button[contains(text(), 'Load More')]\"))\n",
    "                )\n",
    "\n",
    "                # Scroll to the button\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", load_more_button)\n",
    "                time.sleep(0.5)  # Brief pause for scrolling\n",
    "\n",
    "                # Click the button\n",
    "                logger.info(\"Clicking 'Next' or 'Load More' button\")\n",
    "                load_more_button.click()\n",
    "\n",
    "                # Wait for new content to load\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    lambda d: len(d.find_elements(By.CLASS_NAME, \"product-base\")) > total_items\n",
    "                )\n",
    "\n",
    "            except TimeoutException:\n",
    "                logger.error(\"Timeout waiting for new content or button\")\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                logger.error(\"No 'Next' or 'Load More' button found\")\n",
    "                break\n",
    "            except ElementClickInterceptedException:\n",
    "                logger.warning(\"Button click intercepted, attempting to handle overlay\")\n",
    "                try:\n",
    "                    driver.execute_script(\"document.querySelector('.overlay').style.display='none';\")\n",
    "                    load_more_button.click()\n",
    "                except:\n",
    "                    logger.error(\"Failed to handle overlay\")\n",
    "                    break\n",
    "\n",
    "        # Save the HTML\n",
    "        logger.info(\"Saving HTML content\")\n",
    "        html = driver.page_source\n",
    "        with open('myntra_women.html', 'w', encoding='utf-8') as f:\n",
    "            f.write(html)\n",
    "        logger.info(f\"Scraping complete. Total items loaded: {total_items}\")\n",
    "\n",
    "    finally:\n",
    "        # Clean up\n",
    "        logger.info(\"Closing WebDriver\")\n",
    "        driver.quit()\n",
    "\n",
    "except WebDriverException as e:\n",
    "    logger.error(f\"Failed to initialize WebDriver: {str(e)}\")\n",
    "    print(\"Please ensure the chromedriver.exe version matches your Chrome browser version and system architecture.\")\n",
    "    print(\"Download the correct version from https://chromedriver.chromium.org/downloads\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
